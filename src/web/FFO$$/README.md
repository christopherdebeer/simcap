# FFO$$

`Status: Research`

**Fist Full Of Dollars** - using the $* family of algorithms for gesture inference from low dimensional observation

## Concept

This research direction explores applying the [$1 Recogniser](https://depts.washington.edu/acelab/proj/dollar/index.html) and related algorithms to SIMCAP's sensor data.

The $-family of gesture recognizers are designed for:

- Simple, efficient gesture recognition
- Low-dimensional input (2D/3D point sequences)
- Minimal training data requirements
- Real-time performance on constrained devices

## Application to SIMCAP

SIMCAP's IMU data could be mapped to gesture templates using:

- **$1** - Single-stroke gestures from accelerometer traces
- **$P** - Point-cloud matching for 3D hand poses
- **$N** - Multi-stroke gesture sequences

This approach offers a lightweight alternative to neural network-based gesture recognition, particularly suitable for on-device inference.

## References

- [$1 Unistroke Recognizer](https://depts.washington.edu/acelab/proj/dollar/index.html)
- [$P Point-Cloud Recognizer](https://depts.washington.edu/acelab/proj/dollar/pdollar.html)
- [$N Multistroke Recognizer](https://depts.washington.edu/acelab/proj/dollar/ndollar.html)

---

[‚Üê Back to SIMCAP](../../../)
